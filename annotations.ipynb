{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the various named entities such as person, organization, location, date, time, and GPE.\n",
    "\n",
    "For entities that are not correctly identified by the parser, implement a look up search. A look up search essentially cross references entities detected with a dictionary of known entities. You will need to create the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Wikipedia/NNP)\n",
      "  model/NN\n",
      "  review/NN\n",
      "  has/VBZ\n",
      "  falsehoods/NNS\n",
      "  announced/VBN\n",
      "  views/NNS\n",
      "  Wales/VBZ\n",
      "  500/CD\n",
      "  to/TO\n",
      "  non-profit/JJ\n",
      "  quickly/RB\n",
      "  systemic/JJ\n",
      "  ''/''\n",
      "  most/JJS\n",
      "  ’/JJ\n",
      "  Sanger/NNP\n",
      "  comprises/NNS\n",
      "  made/VBD\n",
      "  world/NN\n",
      "  topics/NNS\n",
      "  February/NNP\n",
      "  which/WDT\n",
      "  nearly/RB\n",
      "  an/DT\n",
      "  ./.\n",
      "  2001/CD\n",
      "  in/IN\n",
      "  launched/VBN\n",
      "  one/CD\n",
      "  websites/WDT\n",
      "  were/VBD\n",
      "  The/DT\n",
      "  half/JJ\n",
      "  2014/CD\n",
      "  subject/JJ\n",
      "  2017/CD\n",
      "  and/CC\n",
      "  different/JJ\n",
      "  response/NN\n",
      "  It/PRP\n",
      "  on/IN\n",
      "  Facebook/NNP\n",
      "  biggest/JJS\n",
      "  suitable/JJ\n",
      "  as/IN\n",
      "  ,/,\n",
      "  With/IN\n",
      "  (PERSON Alexa/NNP)\n",
      "  other/JJ\n",
      "  supported/VBD\n",
      "  encyclopedia/RB\n",
      "  stated/VBN\n",
      "  is/VBZ\n",
      "  plan/JJ\n",
      "  mixture/JJ\n",
      "  Wikimedia/NNP\n",
      "  been/VBN\n",
      "  Internet/NNP\n",
      "  15/CD\n",
      "  Time/NNP\n",
      "  English/JJ\n",
      "  vision/NN\n",
      "  encyclopedias/VBD\n",
      "  wiki/RB\n",
      "  more/RBR\n",
      "  exhibiting/JJ\n",
      "  free/JJ\n",
      "  than/IN\n",
      "  criticized/VBN\n",
      "  detect/JJ\n",
      "  news/NN\n",
      "  by/IN\n",
      "  edit/NN\n",
      "  January/NNP\n",
      "  articles/VBZ\n",
      "  its/PRP$\n",
      "  In/IN\n",
      "  some/DT\n",
      "  level/NN\n",
      "  Britannica/NNP\n",
      "  a/DT\n",
      "  testament/NN\n",
      "  (ORGANIZATION YouTube/NNP)\n",
      "  rank/NN\n",
      "  from/IN\n",
      "  best/JJS\n",
      "  2018/CD\n",
      "  million/CD\n",
      "  301/CD\n",
      "  Nature/NNP\n",
      "  anyone/NN\n",
      "  name/NN\n",
      "  good/JJ\n",
      "  openly/RB\n",
      "  being/VBG\n",
      "  spin/JJ\n",
      "  links/NNS\n",
      "  developed/VBD\n",
      "  each/DT\n",
      "  magazine/NN\n",
      "  (PERSON Jimmy/NNP)\n",
      "  science/NN\n",
      "  comparing/VBG\n",
      "  readers/NNS\n",
      "  largest/JJS\n",
      "  Foundation/NN\n",
      "  2005/CD\n",
      "  42/CD\n",
      "  Initially/NNP\n",
      "  billion/CD\n",
      "  controversial/JJ\n",
      "  languages/NNS\n",
      "  40/CD\n",
      "  ‘/NN\n",
      "  policy/NN\n",
      "  ``/``\n",
      "  operates/VBZ\n",
      "  peer/VBP\n",
      "  web-based/JJ\n",
      "  of/IN\n",
      "  English-language/NN\n",
      "  it/PRP\n",
      "  portmanteau/VBZ\n",
      "  month/NN\n",
      "  receives/NNS\n",
      "  presenting/VBG\n",
      "  similar/JJ\n",
      "  approached/VBN\n",
      "  cop/NN\n",
      "  coined/VBN\n",
      "  help/NN\n",
      "  found/VBD\n",
      "  owned/JJ\n",
      "  organization/NN\n",
      "  had/VBD\n",
      "  reference/NN\n",
      "  page/NN\n",
      "  multilingual/JJ\n",
      "  accuracy/NN\n",
      "  content/NN\n",
      "  possibly/RB\n",
      "  truths/VBD\n",
      "  290/CD\n",
      "  headlined/VBD\n",
      "  18/CD\n",
      "  5,721,582/CD\n",
      "  editable/JJ\n",
      "  Overall/JJ\n",
      "  Encyclopædia/NNP\n",
      "  general/NN\n",
      "  based/VBN\n",
      "  donors/NNS\n",
      "  the/DT\n",
      "  (PERSON Larry/NNP)\n",
      "  manipulation/NN\n",
      "  open-door/NN\n",
      "  's/POS\n",
      "  popular/JJ\n",
      "  that/IN\n",
      "  versions/NNS\n",
      "  would/MD\n",
      "  was/VBD\n",
      "  fake/VB\n",
      "  (GPE Washington/NNP)\n",
      "  published/VBN\n",
      "  for/IN\n",
      "  bias/NN\n",
      "  unique/JJ\n",
      "  visitors/NNS\n",
      "  work/VBP\n",
      "  (PERSON Post/NNP)\n",
      "  money/NN\n",
      "  allowing/VBG)\n"
     ]
    }
   ],
   "source": [
    "input_file = \"sample1.txt\"\n",
    "with open(input_file, 'r') as f_in:\n",
    "    data = f_in.read()\n",
    "# print(data)\n",
    "# tokenize\n",
    "tokens = set(nltk.word_tokenize(data))\n",
    "postags = pos_tag(tokens)\n",
    "print(nltk.ne_chunk(postags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Person Wikipedia/NNP)\n",
      "  model/NN\n",
      "  review/NN\n",
      "  has/VBZ\n",
      "  falsehoods/NNS\n",
      "  announced/VBN\n",
      "  views/NNS\n",
      "  Wales/VBZ\n",
      "  500/CD\n",
      "  to/TO\n",
      "  non-profit/JJ\n",
      "  quickly/RB\n",
      "  systemic/JJ\n",
      "  ''/''\n",
      "  most/JJS\n",
      "  ’/JJ\n",
      "  (Person Sanger/NNP)\n",
      "  comprises/NNS\n",
      "  made/VBD\n",
      "  world/NN\n",
      "  topics/NNS\n",
      "  (Person February/NNP)\n",
      "  which/WDT\n",
      "  nearly/RB\n",
      "  an/DT\n",
      "  ./.\n",
      "  2001/CD\n",
      "  in/IN\n",
      "  launched/VBN\n",
      "  one/CD\n",
      "  websites/WDT\n",
      "  were/VBD\n",
      "  The/DT\n",
      "  half/JJ\n",
      "  2014/CD\n",
      "  subject/JJ\n",
      "  2017/CD\n",
      "  and/CC\n",
      "  different/JJ\n",
      "  response/NN\n",
      "  It/PRP\n",
      "  on/IN\n",
      "  (Person Facebook/NNP)\n",
      "  biggest/JJS\n",
      "  suitable/JJ\n",
      "  as/IN\n",
      "  ,/,\n",
      "  With/IN\n",
      "  (Person Alexa/NNP)\n",
      "  other/JJ\n",
      "  supported/VBD\n",
      "  encyclopedia/RB\n",
      "  stated/VBN\n",
      "  is/VBZ\n",
      "  plan/JJ\n",
      "  mixture/JJ\n",
      "  (Person Wikimedia/NNP)\n",
      "  been/VBN\n",
      "  (Person Internet/NNP)\n",
      "  15/CD\n",
      "  (Person Time/NNP)\n",
      "  English/JJ\n",
      "  vision/NN\n",
      "  encyclopedias/VBD\n",
      "  wiki/RB\n",
      "  more/RBR\n",
      "  exhibiting/JJ\n",
      "  free/JJ\n",
      "  than/IN\n",
      "  criticized/VBN\n",
      "  detect/JJ\n",
      "  news/NN\n",
      "  by/IN\n",
      "  edit/NN\n",
      "  (Person January/NNP)\n",
      "  articles/VBZ\n",
      "  its/PRP$\n",
      "  In/IN\n",
      "  some/DT\n",
      "  level/NN\n",
      "  (Person Britannica/NNP)\n",
      "  a/DT\n",
      "  testament/NN\n",
      "  (Person YouTube/NNP)\n",
      "  rank/NN\n",
      "  from/IN\n",
      "  best/JJS\n",
      "  2018/CD\n",
      "  million/CD\n",
      "  301/CD\n",
      "  (Person Nature/NNP)\n",
      "  anyone/NN\n",
      "  name/NN\n",
      "  good/JJ\n",
      "  openly/RB\n",
      "  being/VBG\n",
      "  spin/JJ\n",
      "  links/NNS\n",
      "  developed/VBD\n",
      "  each/DT\n",
      "  magazine/NN\n",
      "  (Person Jimmy/NNP)\n",
      "  science/NN\n",
      "  comparing/VBG\n",
      "  readers/NNS\n",
      "  largest/JJS\n",
      "  Foundation/NN\n",
      "  2005/CD\n",
      "  42/CD\n",
      "  (Person Initially/NNP)\n",
      "  billion/CD\n",
      "  controversial/JJ\n",
      "  languages/NNS\n",
      "  40/CD\n",
      "  ‘/NN\n",
      "  policy/NN\n",
      "  ``/``\n",
      "  operates/VBZ\n",
      "  peer/VBP\n",
      "  web-based/JJ\n",
      "  of/IN\n",
      "  English-language/NN\n",
      "  it/PRP\n",
      "  portmanteau/VBZ\n",
      "  month/NN\n",
      "  receives/NNS\n",
      "  presenting/VBG\n",
      "  similar/JJ\n",
      "  approached/VBN\n",
      "  cop/NN\n",
      "  coined/VBN\n",
      "  help/NN\n",
      "  found/VBD\n",
      "  owned/JJ\n",
      "  organization/NN\n",
      "  had/VBD\n",
      "  reference/NN\n",
      "  page/NN\n",
      "  multilingual/JJ\n",
      "  accuracy/NN\n",
      "  content/NN\n",
      "  possibly/RB\n",
      "  truths/VBD\n",
      "  290/CD\n",
      "  headlined/VBD\n",
      "  18/CD\n",
      "  5,721,582/CD\n",
      "  editable/JJ\n",
      "  Overall/JJ\n",
      "  (Person Encyclopædia/NNP)\n",
      "  general/NN\n",
      "  based/VBN\n",
      "  donors/NNS\n",
      "  the/DT\n",
      "  (Person Larry/NNP)\n",
      "  manipulation/NN\n",
      "  open-door/NN\n",
      "  's/POS\n",
      "  popular/JJ\n",
      "  that/IN\n",
      "  versions/NNS\n",
      "  would/MD\n",
      "  was/VBD\n",
      "  fake/VB\n",
      "  (Person Washington/NNP)\n",
      "  published/VBN\n",
      "  for/IN\n",
      "  bias/NN\n",
      "  unique/JJ\n",
      "  visitors/NNS\n",
      "  work/VBP\n",
      "  (Person Post/NNP)\n",
      "  money/NN\n",
      "  allowing/VBG)\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"Place: {<NNP><NNPS>+}\n",
    "           Date: {<NNP><CD><,><CD>}\n",
    "           Person: {<NNP>+}\n",
    "           \"\"\"\n",
    "regex_parser = nltk.RegexpParser(grammar=grammar)\n",
    "parse_data = regex_parser.parse(postags)\n",
    "print(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
